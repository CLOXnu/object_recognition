{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda29358b314876471fa2bf956c74569a96",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3670"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_root = pathlib.Path(\"flower_photos\")\n",
    "all_img_path = list(img_root.glob('*/*'))\n",
    "# cast to str\n",
    "all_img_path = [str(onePath) for onePath in all_img_path]\n",
    "random.shuffle(all_img_path)\n",
    "\n",
    "len(all_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(root_item.name for root_item in img_root.glob('*/') if root_item.is_dir())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index = dict((name, index) for index, name in enumerate(labels))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[4, 0, 2, 4, 4, 0, 3, 2, 3, 2]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_index = [label_to_index[pathlib.Path(onepath).parent.name] for onepath in all_img_path]\n",
    "all_image_index[:10]\n",
    "# label_list = list(labels)\n",
    "# for oneindex in all_image_index[:10]:\n",
    "#     print(label_list[oneindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, [192, 192])\n",
    "    image /= 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<TensorSliceDataset shapes: (), types: tf.string>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(all_img_path)\n",
    "path_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_ds = tf.data.Dataset.from_tensor_slices([load_image(onepath) for onepath in all_img_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_index, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_index_ds = tf.data.Dataset.zip((image_ds, index_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_index_ds = tf.data.Dataset.from_tensor_slices((all_img_path, all_image_index))\n",
    "\n",
    "def pathIndex_to_imageIndex(path, index):\n",
    "    return load_image(path), index\n",
    "\n",
    "image_index_ds = path_index_ds.map(pathIndex_to_imageIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<MapDataset shapes: ((192, 192, None), ()), types: (tf.float32, tf.int32)>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_index_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: ((None, 192, 192, None), (None,)), types: (tf.float32, tf.int32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "ds = image_index_ds.shuffle(buffer_size=len(all_img_path))\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# 当模型在训练的时候，`prefetch` 使数据集在后台取得 batch。\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "mobile_net.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_range(image, index):\n",
    "  return 2*image-1, index\n",
    "\n",
    "ds = ds.map(change_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([32, 6, 6, 1280])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(ds))\n",
    "feature_map_batch = mobile_net(image_batch)\n",
    "feature_map_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  mobile_net,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(len(labels), activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_192 (Model) (None, 6, 6, 1280)        2257984   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1280)              0         \n_________________________________________________________________\ndense (Dense)                (None, 5)                 6405      \n=================================================================\nTotal params: 2,264,389\nTrainable params: 6,405\nNon-trainable params: 2,257,984\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train for 3 steps\nEpoch 1/10\n3/3 [==============================] - 13s 4s/step - loss: 1.5462 - accuracy: 0.3542\nEpoch 2/10\n3/3 [==============================] - 2s 814ms/step - loss: 1.4848 - accuracy: 0.3333\nEpoch 3/10\n3/3 [==============================] - 2s 787ms/step - loss: 1.3745 - accuracy: 0.3958\nEpoch 4/10\n3/3 [==============================] - 2s 778ms/step - loss: 1.2015 - accuracy: 0.4896\nEpoch 5/10\n3/3 [==============================] - 2s 787ms/step - loss: 1.1197 - accuracy: 0.5417\nEpoch 6/10\n3/3 [==============================] - 2s 785ms/step - loss: 1.0425 - accuracy: 0.6250\nEpoch 7/10\n3/3 [==============================] - 2s 827ms/step - loss: 0.9446 - accuracy: 0.6354\nEpoch 8/10\n3/3 [==============================] - 2s 798ms/step - loss: 1.0193 - accuracy: 0.6771\nEpoch 9/10\n3/3 [==============================] - 2s 780ms/step - loss: 0.9119 - accuracy: 0.6562\nEpoch 10/10\n3/3 [==============================] - 2s 774ms/step - loss: 0.8851 - accuracy: 0.7292\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1336f55d0>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log = model.fit(ds, epochs=10, steps_per_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(path):\n",
    "    display.display(display.Image(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    imgpath = random.choice(all_img_path)\n",
    "    showImage(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}